import json
import numpy as np
import pika
import joblib
import time
import os

# -----------------------------
# Konfiguracja RabbitMQ
# -----------------------------
RABBITMQ_HOST = os.getenv("RABBITMQ_HOST", "rabbitmq")
RABBITMQ_PORT = int(os.getenv("RABBITMQ_PORT", 5672))
RABBITMQ_USER = os.getenv("RABBITMQ_USER", "admin")
RABBITMQ_PASS = os.getenv("RABBITMQ_PASS", "admin123")

QUEUE_INPUT = os.getenv("QUEUE_INPUT", "ml_input")
QUEUE_OUTPUT = os.getenv("QUEUE_OUTPUT", "output")

# -----------------------------
# Funkcja ≈ÇƒÖczenia z RabbitMQ z retry
# -----------------------------
def connect_rabbitmq(max_retries=10):
    credentials = pika.PlainCredentials(RABBITMQ_USER, RABBITMQ_PASS)
    for i in range(max_retries):
        try:
            connection = pika.BlockingConnection(
                pika.ConnectionParameters(
                    host=RABBITMQ_HOST,
                    port=RABBITMQ_PORT,
                    credentials=credentials
                )
            )
            print(f"‚úÖ Po≈ÇƒÖczono z RabbitMQ: {RABBITMQ_HOST}:{RABBITMQ_PORT}")
            return connection
        except Exception as e:
            print(f"‚ùå Pr√≥ba {i+1}/{max_retries} - B≈ÇƒÖd po≈ÇƒÖczenia: {e}")
            time.sleep(5)
    raise Exception("Nie uda≈Ço siƒô po≈ÇƒÖczyƒá z RabbitMQ")

# -----------------------------
# Wczytanie modelu ML
# -----------------------------
model = joblib.load("model.joblib")
print("‚úÖ Model ML za≈Çadowany")

# -----------------------------
# Po≈ÇƒÖczenie z RabbitMQ i deklaracja kolejek
# -----------------------------
connection = connect_rabbitmq()
channel = connection.channel()

# Deklaracja kolejek input/output
channel.queue_declare(queue=QUEUE_INPUT, durable=True)
channel.queue_declare(queue=QUEUE_OUTPUT, durable=True)

print(f"üîÑ Czekam na dane w kolejce '{QUEUE_INPUT}'...")

# -----------------------------
# Funkcja callback - nas≈Çuch input
# -----------------------------
def callback(ch, method, properties, body):
    try:
        # Zamiana JSON ‚Üí dict
        data = json.loads(body)
        print(f"üì• Odebrano: {data}")
        
        # Przygotowanie danych dla modelu ML
        x = np.array(data["input"], dtype=np.float32).reshape(1, -1)
        
        # Predykcja
        y = model.predict(x)[0].tolist()
        
        # Przygotowanie wyniku
        result = {
            "input": data["input"],
            "output": y,
            "timestamp": data.get("timestamp", "")
        }
        
        # Wys≈Çanie wyniku do kolejki ml_output
        channel.basic_publish(
            exchange="",
            routing_key=QUEUE_OUTPUT,
            body=json.dumps(result),
            properties=pika.BasicProperties(delivery_mode=2)  # trwa≈Çe wiadomo≈õci
        )
        
        print(f"‚úÖ Predykcja: IN={data['input']} ‚Üí OUT={y}")
        
        # Potwierdzenie przetworzenia wiadomo≈õci
        ch.basic_ack(delivery_tag=method.delivery_tag)
        
    except Exception as e:
        print(f"‚ùå B≈ÅƒÑD podczas przetwarzania: {e}")
        ch.basic_nack(delivery_tag=method.delivery_tag, requeue=False)

# -----------------------------
# Nas≈Çuchiwanie kolejki ml_input
# -----------------------------
channel.basic_qos(prefetch_count=1)  # jedna wiadomo≈õƒá naraz
channel.basic_consume(queue=QUEUE_INPUT, on_message_callback=callback)

# -----------------------------
# Start pƒôtli nas≈ÇuchujƒÖcej
# -----------------------------
print("üöÄ AI Service uruchomiony!")
channel.start_consuming()
